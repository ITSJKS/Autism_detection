{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "837JjOEnoIeE",
        "outputId": "b79c3d81-6f15-4ba9-ff52-772492d77393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J4kllbmmExw",
        "outputId": "90306b7d-f6fb-4079-fbd0-f551e1d525e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.9.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/33.6 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.9.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from mediapipe.python.solutions.drawing_utils import _normalized_to_pixel_coordinates\n"
      ],
      "metadata": {
        "id": "8QzQ5WwsmNFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_face_detection = mp.solutions.face_detection\n",
        "\n",
        "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils"
      ],
      "metadata": {
        "id": "5_dtmVC4mNvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "imgs = []\n",
        "path = \"/content/drive/MyDrive/autistic-children-facial-data-set/train/autistic/*.*\"\n",
        "for file in glob.glob(path):\n",
        "  #  print(file)\n",
        "   sample_img= cv2.imread(file)\n",
        "   imgs.append(sample_img)\n",
        "  #  plt.figure(figsize = [5, 5])\n",
        "  #  plt.title(\"Sample Image\");\n",
        "  #  plt.axis('off');\n",
        "  #  plt.imshow(sample_img[:,:,::-1]);\n",
        "  #  plt.show() "
      ],
      "metadata": {
        "id": "PoNIQx3aooap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i  = 0;\n",
        "for sample_img in imgs:\n",
        "  face_detection_results = face_detection.process(sample_img[:,:,::-1])\n",
        "\n",
        "  # if face_detection_results.detections:\n",
        "\n",
        "  #     for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "  #         print(f'FACE NUMBER: {face_no+1}')\n",
        "  #         print('==============================')\n",
        "\n",
        "  #         print(f'FACE CONFIDENCE: {round(face.score[0], 2)}')\n",
        "\n",
        "  #         face_data = face.location_data\n",
        "\n",
        "  #         print(f'nFACE BOUNDING BOX:n{face_data.relative_bounding_box}')\n",
        "\n",
        "  #         for i in range(2):\n",
        "\n",
        "  #             print(f'{mp_face_detection.FaceKeyPoint(i).name}:')\n",
        "  #             print(f'{face_data.relative_keypoints[mp_face_detection.FaceKeyPoint(i).value]}')\n",
        "  img_copy = sample_img[:,:,::-1].copy()\n",
        "\n",
        "  if face_detection_results.detections:\n",
        "\n",
        "      for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "          mp_drawing.draw_detection(image=img_copy, detection=face, \n",
        "                                  keypoint_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0),\n",
        "                                                                                thickness=2,\n",
        "                                                                                circle_radius=2))\n",
        "  # fig = plt.figure(figsize = [10, 10])\n",
        "\n",
        "  # plt.title(\"Resultant Image\");plt.axis('off');plt.imshow(img_copy);plt.show()\n",
        "  from PIL import Image\n",
        "  import numpy as np\n",
        "\n",
        "  relative_bounding_box = face_data.relative_bounding_box\n",
        "  image_rows, image_cols, _= img_copy.shape\n",
        "  # image_input = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
        "  # print(relative_bounding_box)\n",
        "  rect_start_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
        "      image_rows)\n",
        "  rect_end_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin + relative_bounding_box.width,\n",
        "      relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
        "      image_rows)\n",
        "  # print(rect_start_point)\n",
        "  # print(rect_end_point)\n",
        "  # Lets draw a bounding box\n",
        "  color = (255, 255, 255)\n",
        "  thickness = 2\n",
        "  cv2.rectangle(img_copy, rect_start_point, rect_end_point, color, thickness)\n",
        "  xleft,ytop=rect_start_point\n",
        "  xright,ybot=rect_end_point\n",
        "  crop_img = img_copy[ytop: ybot, xleft: xright]\n",
        "  cv2.imwrite(f'/content/drive/MyDrive/cropped-imgs/train/autistic/{i}.jpg', crop_img)\n",
        "  i =  i + 1"
      ],
      "metadata": {
        "id": "m7TMOP8uq5AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "imgs = []\n",
        "path = \"/content/drive/MyDrive/autistic-children-facial-data-set/train/non_autistic/*.*\"\n",
        "for file in glob.glob(path):\n",
        "  #  print(file)\n",
        "   sample_img= cv2.imread(file)\n",
        "   imgs.append(sample_img)\n",
        "  #  plt.figure(figsize = [5, 5])\n",
        "  #  plt.title(\"Sample Image\");\n",
        "  #  plt.axis('off');\n",
        "  #  plt.imshow(sample_img[:,:,::-1]);\n",
        "  #  plt.show() "
      ],
      "metadata": {
        "id": "xsh8gZE-8UYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i  = 0;\n",
        "for sample_img in imgs:\n",
        "  face_detection_results = face_detection.process(sample_img[:,:,::-1])\n",
        "\n",
        "  # if face_detection_results.detections:\n",
        "\n",
        "  #     for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "  #         print(f'FACE NUMBER: {face_no+1}')\n",
        "  #         print('==============================')\n",
        "\n",
        "  #         print(f'FACE CONFIDENCE: {round(face.score[0], 2)}')\n",
        "\n",
        "  #         face_data = face.location_data\n",
        "\n",
        "  #         print(f'nFACE BOUNDING BOX:n{face_data.relative_bounding_box}')\n",
        "\n",
        "  #         for i in range(2):\n",
        "\n",
        "  #             print(f'{mp_face_detection.FaceKeyPoint(i).name}:')\n",
        "  #             print(f'{face_data.relative_keypoints[mp_face_detection.FaceKeyPoint(i).value]}')\n",
        "  img_copy = sample_img[:,:,::-1].copy()\n",
        "\n",
        "  if face_detection_results.detections:\n",
        "\n",
        "      for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "          mp_drawing.draw_detection(image=img_copy, detection=face, \n",
        "                                  keypoint_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0),\n",
        "                                                                                thickness=2,\n",
        "                                                                                circle_radius=2))\n",
        "  # fig = plt.figure(figsize = [10, 10])\n",
        "\n",
        "  # plt.title(\"Resultant Image\");plt.axis('off');plt.imshow(img_copy);plt.show()\n",
        "  from PIL import Image\n",
        "  import numpy as np\n",
        "\n",
        "  relative_bounding_box = face_data.relative_bounding_box\n",
        "  image_rows, image_cols, _= img_copy.shape\n",
        "  # image_input = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
        "  # print(relative_bounding_box)\n",
        "  rect_start_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
        "      image_rows)\n",
        "  rect_end_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin + relative_bounding_box.width,\n",
        "      relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
        "      image_rows)\n",
        "  # print(rect_start_point)\n",
        "  # print(rect_end_point)\n",
        "  # Lets draw a bounding box\n",
        "  color = (255, 255, 255)\n",
        "  thickness = 2\n",
        "  cv2.rectangle(img_copy, rect_start_point, rect_end_point, color, thickness)\n",
        "  xleft,ytop=rect_start_point\n",
        "  xright,ybot=rect_end_point\n",
        "  crop_img = img_copy[ytop: ybot, xleft: xright]\n",
        "  cv2.imwrite(f'/content/drive/MyDrive/cropped-imgs/train/non_autistic/{i}.jpg', crop_img)\n",
        "  i =  i + 1"
      ],
      "metadata": {
        "id": "0Us9t4Q76CqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "imgs = []\n",
        "path = \"/content/drive/MyDrive/autistic-children-facial-data-set/test/non_autistic/*.*\"\n",
        "for file in glob.glob(path):\n",
        "  #  print(file)\n",
        "   sample_img= cv2.imread(file)\n",
        "   imgs.append(sample_img)\n",
        "  #  plt.figure(figsize = [5, 5])\n",
        "  #  plt.title(\"Sample Image\");\n",
        "  #  plt.axis('off');\n",
        "  #  plt.imshow(sample_img[:,:,::-1]);\n",
        "  #  plt.show() "
      ],
      "metadata": {
        "id": "CF2bZXFb9Is2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i  = 0;\n",
        "for sample_img in imgs:\n",
        "  face_detection_results = face_detection.process(sample_img[:,:,::-1])\n",
        "\n",
        "  # if face_detection_results.detections:\n",
        "\n",
        "  #     for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "  #         print(f'FACE NUMBER: {face_no+1}')\n",
        "  #         print('==============================')\n",
        "\n",
        "  #         print(f'FACE CONFIDENCE: {round(face.score[0], 2)}')\n",
        "\n",
        "  #         face_data = face.location_data\n",
        "\n",
        "  #         print(f'nFACE BOUNDING BOX:n{face_data.relative_bounding_box}')\n",
        "\n",
        "  #         for i in range(2):\n",
        "\n",
        "  #             print(f'{mp_face_detection.FaceKeyPoint(i).name}:')\n",
        "  #             print(f'{face_data.relative_keypoints[mp_face_detection.FaceKeyPoint(i).value]}')\n",
        "  img_copy = sample_img[:,:,::-1].copy()\n",
        "\n",
        "  if face_detection_results.detections:\n",
        "\n",
        "      for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "          mp_drawing.draw_detection(image=img_copy, detection=face, \n",
        "                                  keypoint_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0),\n",
        "                                                                                thickness=2,\n",
        "                                                                                circle_radius=2))\n",
        "  # fig = plt.figure(figsize = [10, 10])\n",
        "\n",
        "  # plt.title(\"Resultant Image\");plt.axis('off');plt.imshow(img_copy);plt.show()\n",
        "  from PIL import Image\n",
        "  import numpy as np\n",
        "\n",
        "  relative_bounding_box = face_data.relative_bounding_box\n",
        "  image_rows, image_cols, _= img_copy.shape\n",
        "  # image_input = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
        "  # print(relative_bounding_box)\n",
        "  rect_start_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
        "      image_rows)\n",
        "  rect_end_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin + relative_bounding_box.width,\n",
        "      relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
        "      image_rows)\n",
        "  # print(rect_start_point)\n",
        "  # print(rect_end_point)\n",
        "  # Lets draw a bounding box\n",
        "  color = (255, 255, 255)\n",
        "  thickness = 2\n",
        "  cv2.rectangle(img_copy, rect_start_point, rect_end_point, color, thickness)\n",
        "  xleft,ytop=rect_start_point\n",
        "  xright,ybot=rect_end_point\n",
        "  crop_img = img_copy[ytop: ybot, xleft: xright]\n",
        "  cv2.imwrite(f'/content/drive/MyDrive/cropped-imgs/test/non_autistic/{i}.jpg', crop_img)\n",
        "  i =  i + 1"
      ],
      "metadata": {
        "id": "7zkXZyMm9I9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "imgs = []\n",
        "path = \"/content/drive/MyDrive/autistic-children-facial-data-set/test/autistic/*.*\"\n",
        "for file in glob.glob(path):\n",
        "  #  print(file)\n",
        "   sample_img= cv2.imread(file)\n",
        "   imgs.append(sample_img)\n",
        "  #  plt.figure(figsize = [5, 5])\n",
        "  #  plt.title(\"Sample Image\");\n",
        "  #  plt.axis('off');\n",
        "  #  plt.imshow(sample_img[:,:,::-1]);\n",
        "  #  plt.show() "
      ],
      "metadata": {
        "id": "_oWDXzBg9JKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i  = 0;\n",
        "for sample_img in imgs:\n",
        "  face_detection_results = face_detection.process(sample_img[:,:,::-1])\n",
        "\n",
        "  # if face_detection_results.detections:\n",
        "\n",
        "  #     for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "  #         print(f'FACE NUMBER: {face_no+1}')\n",
        "  #         print('==============================')\n",
        "\n",
        "  #         print(f'FACE CONFIDENCE: {round(face.score[0], 2)}')\n",
        "\n",
        "  #         face_data = face.location_data\n",
        "\n",
        "  #         print(f'nFACE BOUNDING BOX:n{face_data.relative_bounding_box}')\n",
        "\n",
        "  #         for i in range(2):\n",
        "\n",
        "  #             print(f'{mp_face_detection.FaceKeyPoint(i).name}:')\n",
        "  #             print(f'{face_data.relative_keypoints[mp_face_detection.FaceKeyPoint(i).value]}')\n",
        "  img_copy = sample_img[:,:,::-1].copy()\n",
        "\n",
        "  if face_detection_results.detections:\n",
        "\n",
        "      for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "          mp_drawing.draw_detection(image=img_copy, detection=face, \n",
        "                                  keypoint_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0),\n",
        "                                                                                thickness=2,\n",
        "                                                                                circle_radius=2))\n",
        "  # fig = plt.figure(figsize = [10, 10])\n",
        "\n",
        "  # plt.title(\"Resultant Image\");plt.axis('off');plt.imshow(img_copy);plt.show()\n",
        "  from PIL import Image\n",
        "  import numpy as np\n",
        "\n",
        "  relative_bounding_box = face_data.relative_bounding_box\n",
        "  image_rows, image_cols, _= img_copy.shape\n",
        "  # image_input = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
        "  # print(relative_bounding_box)\n",
        "  rect_start_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
        "      image_rows)\n",
        "  rect_end_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin + relative_bounding_box.width,\n",
        "      relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
        "      image_rows)\n",
        "  # print(rect_start_point)\n",
        "  # print(rect_end_point)\n",
        "  # Lets draw a bounding box\n",
        "  color = (255, 255, 255)\n",
        "  thickness = 2\n",
        "  cv2.rectangle(img_copy, rect_start_point, rect_end_point, color, thickness)\n",
        "  xleft,ytop=rect_start_point\n",
        "  xright,ybot=rect_end_point\n",
        "  crop_img = img_copy[ytop: ybot, xleft: xright]\n",
        "  cv2.imwrite(f'/content/drive/MyDrive/cropped-imgs/test/autistic/{i}.jpg', crop_img)\n",
        "  i =  i + 1"
      ],
      "metadata": {
        "id": "FE2UxhJN9JUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "imgs = []\n",
        "path = \"/content/drive/MyDrive/autistic-children-facial-data-set/valid/autistic/*.*\"\n",
        "for file in glob.glob(path):\n",
        "  #  print(file)\n",
        "   sample_img= cv2.imread(file)\n",
        "   imgs.append(sample_img)\n",
        "  #  plt.figure(figsize = [5, 5])\n",
        "  #  plt.title(\"Sample Image\");\n",
        "  #  plt.axis('off');\n",
        "  #  plt.imshow(sample_img[:,:,::-1]);\n",
        "  #  plt.show() "
      ],
      "metadata": {
        "id": "cZ7IcQ8b_Sl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i  = 0;\n",
        "for sample_img in imgs:\n",
        "  face_detection_results = face_detection.process(sample_img[:,:,::-1])\n",
        "\n",
        "  # if face_detection_results.detections:\n",
        "\n",
        "  #     for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "  #         print(f'FACE NUMBER: {face_no+1}')\n",
        "  #         print('==============================')\n",
        "\n",
        "  #         print(f'FACE CONFIDENCE: {round(face.score[0], 2)}')\n",
        "\n",
        "  #         face_data = face.location_data\n",
        "\n",
        "  #         print(f'nFACE BOUNDING BOX:n{face_data.relative_bounding_box}')\n",
        "\n",
        "  #         for i in range(2):\n",
        "\n",
        "  #             print(f'{mp_face_detection.FaceKeyPoint(i).name}:')\n",
        "  #             print(f'{face_data.relative_keypoints[mp_face_detection.FaceKeyPoint(i).value]}')\n",
        "  img_copy = sample_img[:,:,::-1].copy()\n",
        "\n",
        "  if face_detection_results.detections:\n",
        "\n",
        "      for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "          mp_drawing.draw_detection(image=img_copy, detection=face, \n",
        "                                  keypoint_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0),\n",
        "                                                                                thickness=2,\n",
        "                                                                                circle_radius=2))\n",
        "  # fig = plt.figure(figsize = [10, 10])\n",
        "\n",
        "  # plt.title(\"Resultant Image\");plt.axis('off');plt.imshow(img_copy);plt.show()\n",
        "  from PIL import Image\n",
        "  import numpy as np\n",
        "\n",
        "  relative_bounding_box = face_data.relative_bounding_box\n",
        "  image_rows, image_cols, _= img_copy.shape\n",
        "  # image_input = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
        "  # print(relative_bounding_box)\n",
        "  rect_start_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
        "      image_rows)\n",
        "  rect_end_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin + relative_bounding_box.width,\n",
        "      relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
        "      image_rows)\n",
        "  # print(rect_start_point)\n",
        "  # print(rect_end_point)\n",
        "  # Lets draw a bounding box\n",
        "  color = (255, 255, 255)\n",
        "  thickness = 2\n",
        "  cv2.rectangle(img_copy, rect_start_point, rect_end_point, color, thickness)\n",
        "  xleft,ytop=rect_start_point\n",
        "  xright,ybot=rect_end_point\n",
        "  crop_img = img_copy[ytop: ybot, xleft: xright]\n",
        "  cv2.imwrite(f'/content/drive/MyDrive/cropped-imgs/valid/autistic/{i}.jpg', crop_img)\n",
        "  i =  i + 1"
      ],
      "metadata": {
        "id": "XjdcbT9y_WLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "imgs = []\n",
        "path = \"/content/drive/MyDrive/autistic-children-facial-data-set/valid/non_autistic/*.*\"\n",
        "for file in glob.glob(path):\n",
        "  #  print(file)\n",
        "   sample_img= cv2.imread(file)\n",
        "   imgs.append(sample_img)\n",
        "  #  plt.figure(figsize = [5, 5])\n",
        "  #  plt.title(\"Sample Image\");\n",
        "  #  plt.axis('off');\n",
        "  #  plt.imshow(sample_img[:,:,::-1]);\n",
        "  #  plt.show() "
      ],
      "metadata": {
        "id": "xybl5pqB_X_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i  = 0;\n",
        "for sample_img in imgs:\n",
        "  face_detection_results = face_detection.process(sample_img[:,:,::-1])\n",
        "\n",
        "  # if face_detection_results.detections:\n",
        "\n",
        "  #     for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "  #         print(f'FACE NUMBER: {face_no+1}')\n",
        "  #         print('==============================')\n",
        "\n",
        "  #         print(f'FACE CONFIDENCE: {round(face.score[0], 2)}')\n",
        "\n",
        "  #         face_data = face.location_data\n",
        "\n",
        "  #         print(f'nFACE BOUNDING BOX:n{face_data.relative_bounding_box}')\n",
        "\n",
        "  #         for i in range(2):\n",
        "\n",
        "  #             print(f'{mp_face_detection.FaceKeyPoint(i).name}:')\n",
        "  #             print(f'{face_data.relative_keypoints[mp_face_detection.FaceKeyPoint(i).value]}')\n",
        "  img_copy = sample_img[:,:,::-1].copy()\n",
        "\n",
        "  if face_detection_results.detections:\n",
        "\n",
        "      for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "          mp_drawing.draw_detection(image=img_copy, detection=face, \n",
        "                                  keypoint_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0),\n",
        "                                                                                thickness=2,\n",
        "                                                                                circle_radius=2))\n",
        "  # fig = plt.figure(figsize = [10, 10])\n",
        "\n",
        "  # plt.title(\"Resultant Image\");plt.axis('off');plt.imshow(img_copy);plt.show()\n",
        "  from PIL import Image\n",
        "  import numpy as np\n",
        "\n",
        "  relative_bounding_box = face_data.relative_bounding_box\n",
        "  image_rows, image_cols, _= img_copy.shape\n",
        "  # image_input = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
        "  # print(relative_bounding_box)\n",
        "  rect_start_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
        "      image_rows)\n",
        "  rect_end_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin + relative_bounding_box.width,\n",
        "      relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
        "      image_rows)\n",
        "  # print(rect_start_point)\n",
        "  # print(rect_end_point)\n",
        "  # Lets draw a bounding box\n",
        "  color = (255, 255, 255)\n",
        "  thickness = 2\n",
        "  cv2.rectangle(img_copy, rect_start_point, rect_end_point, color, thickness)\n",
        "  xleft,ytop=rect_start_point\n",
        "  xright,ybot=rect_end_point\n",
        "  crop_img = img_copy[ytop: ybot, xleft: xright]\n",
        "  cv2.imwrite(f'/content/drive/MyDrive/cropped-imgs/valid/non_autistic/{i}.jpg', crop_img)\n",
        "  i =  i + 1"
      ],
      "metadata": {
        "id": "LnOYCa0i_YPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "imgs = []\n",
        "path = \"/content/drive/MyDrive/autistic-children-facial-data-set/consolidated/autistic/*.*\"\n",
        "for file in glob.glob(path):\n",
        "  #  print(file)\n",
        "   sample_img= cv2.imread(file)\n",
        "   imgs.append(sample_img)\n",
        "  #  plt.figure(figsize = [5, 5])\n",
        "  #  plt.title(\"Sample Image\");\n",
        "  #  plt.axis('off');\n",
        "  #  plt.imshow(sample_img[:,:,::-1]);\n",
        "  #  plt.show() "
      ],
      "metadata": {
        "id": "6oIDAlBm_ckB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i  = 0;\n",
        "for sample_img in imgs:\n",
        "  face_detection_results = face_detection.process(sample_img[:,:,::-1])\n",
        "\n",
        "  # if face_detection_results.detections:\n",
        "\n",
        "  #     for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "  #         print(f'FACE NUMBER: {face_no+1}')\n",
        "  #         print('==============================')\n",
        "\n",
        "  #         print(f'FACE CONFIDENCE: {round(face.score[0], 2)}')\n",
        "\n",
        "  #         face_data = face.location_data\n",
        "\n",
        "  #         print(f'nFACE BOUNDING BOX:n{face_data.relative_bounding_box}')\n",
        "\n",
        "  #         for i in range(2):\n",
        "\n",
        "  #             print(f'{mp_face_detection.FaceKeyPoint(i).name}:')\n",
        "  #             print(f'{face_data.relative_keypoints[mp_face_detection.FaceKeyPoint(i).value]}')\n",
        "  img_copy = sample_img[:,:,::-1].copy()\n",
        "\n",
        "  if face_detection_results.detections:\n",
        "\n",
        "      for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "          mp_drawing.draw_detection(image=img_copy, detection=face, \n",
        "                                  keypoint_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0),\n",
        "                                                                                thickness=2,\n",
        "                                                                                circle_radius=2))\n",
        "  # fig = plt.figure(figsize = [10, 10])\n",
        "\n",
        "  # plt.title(\"Resultant Image\");plt.axis('off');plt.imshow(img_copy);plt.show()\n",
        "  from PIL import Image\n",
        "  import numpy as np\n",
        "\n",
        "  relative_bounding_box = face_data.relative_bounding_box\n",
        "  image_rows, image_cols, _= img_copy.shape\n",
        "  # image_input = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
        "  # print(relative_bounding_box)\n",
        "  rect_start_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
        "      image_rows)\n",
        "  rect_end_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin + relative_bounding_box.width,\n",
        "      relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
        "      image_rows)\n",
        "  # print(rect_start_point)\n",
        "  # print(rect_end_point)\n",
        "  # Lets draw a bounding box\n",
        "  color = (255, 255, 255)\n",
        "  thickness = 2\n",
        "  cv2.rectangle(img_copy, rect_start_point, rect_end_point, color, thickness)\n",
        "  xleft,ytop=rect_start_point\n",
        "  xright,ybot=rect_end_point\n",
        "  crop_img = img_copy[ytop: ybot, xleft: xright]\n",
        "  cv2.imwrite(f'/content/drive/MyDrive/cropped-imgs/consolidated/autistic/{i}.jpg', crop_img)\n",
        "  i =  i + 1"
      ],
      "metadata": {
        "id": "662_z8qG_eZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "imgs = []\n",
        "path = \"/content/drive/MyDrive/autistic-children-facial-data-set/consolidated/non_autistic/*.*\"\n",
        "for file in glob.glob(path):\n",
        "  #  print(file)\n",
        "   sample_img= cv2.imread(file)\n",
        "   imgs.append(sample_img)\n",
        "  #  plt.figure(figsize = [5, 5])\n",
        "  #  plt.title(\"Sample Image\");\n",
        "  #  plt.axis('off');\n",
        "  #  plt.imshow(sample_img[:,:,::-1]);\n",
        "  #  plt.show() "
      ],
      "metadata": {
        "id": "6DUlqNks_0WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i  = 0;\n",
        "for sample_img in imgs:\n",
        "  face_detection_results = face_detection.process(sample_img[:,:,::-1])\n",
        "\n",
        "  # if face_detection_results.detections:\n",
        "\n",
        "  #     for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "  #         print(f'FACE NUMBER: {face_no+1}')\n",
        "  #         print('==============================')\n",
        "\n",
        "  #         print(f'FACE CONFIDENCE: {round(face.score[0], 2)}')\n",
        "\n",
        "  #         face_data = face.location_data\n",
        "\n",
        "  #         print(f'nFACE BOUNDING BOX:n{face_data.relative_bounding_box}')\n",
        "\n",
        "  #         for i in range(2):\n",
        "\n",
        "  #             print(f'{mp_face_detection.FaceKeyPoint(i).name}:')\n",
        "  #             print(f'{face_data.relative_keypoints[mp_face_detection.FaceKeyPoint(i).value]}')\n",
        "  img_copy = sample_img[:,:,::-1].copy()\n",
        "\n",
        "  if face_detection_results.detections:\n",
        "\n",
        "      for face_no, face in enumerate(face_detection_results.detections):\n",
        "\n",
        "          mp_drawing.draw_detection(image=img_copy, detection=face, \n",
        "                                  keypoint_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0),\n",
        "                                                                                thickness=2,\n",
        "                                                                                circle_radius=2))\n",
        "  # fig = plt.figure(figsize = [10, 10])\n",
        "\n",
        "  # plt.title(\"Resultant Image\");plt.axis('off');plt.imshow(img_copy);plt.show()\n",
        "  from PIL import Image\n",
        "  import numpy as np\n",
        "\n",
        "  relative_bounding_box = face_data.relative_bounding_box\n",
        "  image_rows, image_cols, _= img_copy.shape\n",
        "  # image_input = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
        "  # print(relative_bounding_box)\n",
        "  rect_start_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin, relative_bounding_box.ymin, image_cols,\n",
        "      image_rows)\n",
        "  rect_end_point = _normalized_to_pixel_coordinates(\n",
        "      relative_bounding_box.xmin + relative_bounding_box.width,\n",
        "      relative_bounding_box.ymin + relative_bounding_box.height, image_cols,\n",
        "      image_rows)\n",
        "  # print(rect_start_point)\n",
        "  # print(rect_end_point)\n",
        "  # Lets draw a bounding box\n",
        "  color = (255, 255, 255)\n",
        "  thickness = 2\n",
        "  cv2.rectangle(img_copy, rect_start_point, rect_end_point, color, thickness)\n",
        "  xleft,ytop=rect_start_point\n",
        "  xright,ybot=rect_end_point\n",
        "  crop_img = img_copy[ytop: ybot, xleft: xright]\n",
        "  cv2.imwrite(f'/content/drive/MyDrive/cropped-imgs/consolidated/non_autistic/{i}.jpg', crop_img)\n",
        "  i =  i + 1"
      ],
      "metadata": {
        "id": "GD_5nqag_1F7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}